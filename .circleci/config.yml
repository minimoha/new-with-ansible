# # Use the latest 2.1 version of CircleCI pipeline process engine.
# # See: https://circleci.com/docs/2.0/configuration-reference
# version: 2.1

# # Define a job to be invoked later in a workflow.
# # See: https://circleci.com/docs/2.0/configuration-reference/#jobs
# jobs:
#   say-hello:
#     # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
#     # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
#     docker:
#       - image: cimg/base:stable
#     # Add steps to the job
#     # See: https://circleci.com/docs/2.0/configuration-reference/#steps
#     steps:
#       - checkout
#       - run:
#           name: "Say hello"
#           command: "echo Hello, World!"

# # Invoke jobs via workflows
# # See: https://circleci.com/docs/2.0/configuration-reference/#workflows
# workflows:
#   say-hello-workflow:
#     jobs:
#       - say-hello


version: 2.1
# Use a package of configuration called an orb.
orbs:
  # Choose either one of the orbs below
  # welcome: circleci/welcome-orb@0.4.1
  # aws-cli: circleci/aws-cli@2.0.3
# Define the jobs we want to run for this project
commands:
   # Exercise - Rollback
   destroy_environment:
     steps:
       - run:
           name: Destroy environment
           # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
           # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
           when: on_fail
           command: |
             aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7}

jobs:
    create_infrastructure: 
      docker:
        - image: amazon/aws-cli
      steps:
        - checkout
        - run:
            name: Create Cloudformation Stack
            command: |
              aws cloudformation deploy \
                --template-file template.yml \
                --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7} \
                --region us-east-1
        - run: exit 1
        - destroy_environment
    
    # Exercise: Config and Deployment
    configure_infrastructure: 
      docker:
        - image: cimg/python:3.10
      steps:
        - checkout
        - add_ssh_keys:
                # You can get this ID in the section where you registered the SSH Key
                fingerprints:
                  - "6a:f5:5e:97:ed:95:5c:6e:a2:75:34:61:8d:d9:94:72"
        - run:
            name: Install Ansible
            command: |
              # Install Ansible
              pip3 install ansible
        - run:
            name: Run Playbook and Configure server
            command: |
              # Your command
              ansible-playbook -i inventory main-remote.yml

  # Exercise: Smoke Testing
    # smoke_test:
    #   docker:
    #     - image: alpine:latest
    #   steps:
    #     - run: apk add --update curl
    #     - run:
    #         name: smoke test
    #         command: |
    #           URL="https://blog.udacity.com/"
    #           # Test if website exists
    #           if curl -s --head ${URL}
    #           then
    #             return 0
    #           else
    #             return 1
    #           fi

    smoke_test:
      docker:
        - image: alpine:latest
      steps:
        - run:
            name: smoke test
            command: |
              return 1
        - destroy_environment


    # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
    # Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
    create_and_deploy_front_end:
      docker:
        - image: amazon/aws-cli
      steps:
        - checkout
        - run:
            name: Execute bucket.yml - Create Cloudformation Stack
            command: |
              aws cloudformation deploy \
              --template-file bucket.yml \
              --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
              --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
        # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
        - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete
    
    # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
    get_last_deployment_id:
      docker:
        - image: amazon/aws-cli
      steps:
        - checkout
        - run: yum install -y tar gzip
        - run:
            name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
            command: |
              aws cloudformation \
              list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
              --no-paginate --output text > ~/textfile.txt
        - persist_to_workspace:
            root: ~/
            paths: 
              - textfile.txt 

    # Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
    # Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
    promote_to_production:
      docker:
        - image: amazon/aws-cli
      steps:
        - checkout
        - run:
            name: Execute cloudfront.yml
            command: |
              aws cloudformation deploy \
              --template-file cloudfront.yml \
              --stack-name production-distro \
              --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

    # Destroy the previous production version's S3 bucket and CloudFormation stack. 
    clean_up_old_front_end:
      docker:
        - image: amazon/aws-cli
      steps:
        - checkout
        - run: yum install -y tar gzip
        - attach_workspace:
            at: ~/
        - run:
            name: Destroy the previous S3 bucket and CloudFormation stack. 
            # Use $OldBucketID environment variable or mybucket644752792305 below.
            # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
            command: |
              export OldBucketID=$(cat ~/textfile.txt)
              aws s3 rm "s3://${OldBucketID}" --recursive

          
# Sequential workflow
workflows:
  # Name the workflow
  myWorkflow:
    jobs:
      #- create_infrastructure
     # - configure_infrastructure
      # - smoke_test:
      #     requires:
      #      - create_infrastructure
      - create_and_deploy_front_end
      - promote_to_production:
          requires: 
            - create_and_deploy_front_end
      - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production